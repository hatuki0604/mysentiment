import streamlit as st
import sys
from pathlib import Path
import re
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss

# ================== PATH & IMPORT RAG ==================
FILE_DIR = Path(__file__).resolve()
MODULE_DIR = FILE_DIR.parent        # M4_Rag_qa/
PROJECT_ROOT = FILE_DIR.parents[1]  # app_reviews_pipeline/
sys.path.append(str(MODULE_DIR))
sys.path.append(str(PROJECT_ROOT))

from rag_qa import (
    chunk_text,
    retrieve_top_k,
    generate_answer,
    sanitize,
    MODEL_NAME,
)
from llm_config import get_llm

# ================== PAGE CONFIG ==================
st.set_page_config(page_title="RAG QA Demo", page_icon="üîç", layout="centered")

# ================== SESSION STATE INIT & CLEAR HANDLING ==================

# Kh·ªüi t·∫°o c·ªù clear n·∫øu ch∆∞a c√≥
if "clear_triggered" not in st.session_state:
    st.session_state["clear_triggered"] = False

# N·∫øu ·ªü v√≤ng rerun n√†y ƒëang c√≥ y√™u c·∫ßu clear ‚Üí reset query_box TR∆Ø·ªöC KHI T·∫†O text_input
if st.session_state["clear_triggered"]:
    st.session_state["query_box"] = ""
    st.session_state["clear_triggered"] = False

# ================== CONFIG ==================
DATA_CSV = "/Users/hatrungkien/my-sentiment/data/processed/processed_tgdd_reviews.csv"
DS_NAME = "processed_tgdd_reviews"
PROVIDER = "openai"
MODEL = "gpt-4o-mini"
chat_fn = get_llm(PROVIDER, MODEL)

# ================== LOAD RAG (cache) ==================
@st.cache_resource(show_spinner=True)
def load_rag_system():
    df = pd.read_csv(DATA_CSV, usecols=["review_id", "review_text"])

    key = f"{DS_NAME}__{MODEL_NAME.split('/')[-1]}__{PROVIDER}__{sanitize(MODEL)}"
    cache_dir = Path(PROJECT_ROOT).parent / "outputs" / "rag_cache" / key
    cache_dir.mkdir(parents=True, exist_ok=True)

    chunks_path = cache_dir / "chunks.csv"
    emb_path = cache_dir / "embeddings.npy"
    index_path = cache_dir / "index.faiss"

    embed_model = SentenceTransformer(MODEL_NAME)

    if chunks_path.exists() and emb_path.exists() and index_path.exists():
        chunks_df = pd.read_csv(chunks_path)
        chunks = chunks_df.to_dict("records")
        embeddings = np.load(emb_path)
        index = faiss.read_index(str(index_path))
        return df, chunks, embeddings, index, embed_model

    # build m·ªõi
    chunks = []
    for _, row in df.iterrows():
        for sub in chunk_text(str(row["review_text"])):
            if sub.strip():
                chunks.append({"review_id": row["review_id"], "text": sub})

    texts = [c["text"] for c in chunks]
    embs = []
    batch_size = 512
    for i in range(0, len(texts), batch_size):
        b = embed_model.encode(texts[i:i+batch_size], convert_to_numpy=True)
        embs.append(b)
    embeddings = np.vstack(embs)
    faiss.normalize_L2(embeddings)
    index = faiss.IndexFlatIP(embeddings.shape[1])
    index.add(embeddings)

    pd.DataFrame(chunks).to_csv(chunks_path, index=False)
    np.save(emb_path, embeddings)
    faiss.write_index(index, str(index_path))

    return df, chunks, embeddings, index, embed_model

# ================== CSS CHO N√öT ==================
st.markdown("""
    <style>
        .big-btn {
            height: 48px !important;
            width: 100% !important;
            font-size: 16px !important;
            border-radius: 8px !important;
        }
        .btn-submit {
            background-color: #ff4b4b !important;
            color: red !important;
            border: none !important;
        }
        .btn-clear {
            background-color: #f1f1f1 !important;
            color: #333 !important;
            border: 1px solid #dcdcdc !important;
        }
        .btn-submit:hover {
        background-color: #e84343 !important;
}

    </style>
""", unsafe_allow_html=True)

# ================== UI ==================
st.title("Demo RAG QA from User's Reviews")
st.caption("H·ªá th·ªëng truy v·∫•n")

with st.spinner("ƒêang load h·ªá th·ªëng..."):
    df, chunks, embeddings, index, embed_model = load_rag_system()

st.divider()

# ---- FORM: Enter = Submit ----
with st.form("rag_form"):
    query = st.text_input("Nh·∫≠p truy v·∫•n:", "", key="query_box")

    # h√†ng n√∫t ‚Äì 2 n√∫t + 1 c·ªôt tr·ªëng ƒë·ªÉ n√∫t nh·ªè l·∫°i
    col1, col2, _ = st.columns([1, 1, 4])
    with col1:
        submit = st.form_submit_button("Submit", use_container_width=True)
    with col2:
        clear = st.form_submit_button("Clear", use_container_width=True)

# style cho n√∫t sau khi render
st.markdown("""
<script>
const submitBtn = window.parent.document.querySelector('button[data-testid="baseButton-rag_form-Submit"]');
if (submitBtn) submitBtn.classList.add('big-btn', 'btn-submit');
const clearBtn = window.parent.document.querySelector('button[data-testid="baseButton-rag_form-Clear"]');
if (clearBtn) clearBtn.classList.add('big-btn', 'btn-clear');
</script>
""", unsafe_allow_html=True)

# ================== CLEAR: set c·ªù & RERUN ==================
if clear:
    st.session_state["clear_triggered"] = True
    st.rerun()

# ================== SUBMIT: x·ª≠ l√Ω truy v·∫•n ==================
if submit and query.strip():
    q = query.strip()

    if q.lower().startswith("summary:") or "overview" in q.lower():
        request_type = "summary"
        q_clean = re.sub(r"^(summary:|overview of|t√≥m t·∫Øt)\s*", "", q, flags=re.I).strip()
        k = 50
    else:
        request_type = "answer"
        q_clean = q
        k = 15

    with st.spinner("ƒêang retrieve top-K..."):
        topk = retrieve_top_k(q_clean, embed_model, index, chunks, k=k)

    with st.spinner("ƒêang truy v·∫•n..."):
        answer = generate_answer(
            query=q_clean,
            retrieved=topk,
            dataset_name=DS_NAME,
            request_type=request_type,
            chat_fn=chat_fn,
        )

    st.subheader("K·∫øt qu·∫£:")
    st.write(answer)
